# PPIO Claude Sonnet 4.5 SWE-bench 评估性能分析报告

## 概述

本报告分析了 PPIO Claude Sonnet 4.5 在 SWE-bench Verified 评估中的时间消耗分布，识别性能瓶颈，并提出优化建议。

**评估结果**: 314/487 (64.5%) 准确率
**总耗时**: ~16 小时
**实例数量**: 500

---

## 第一部分：时间消耗分解

### 1.1 整体时间分布

| 组件 | 耗时 | 占比 | 说明 |
|------|------|------|------|
| LLM API 调用 (并行) | ~12.3 小时 | 76.6% | 8 workers 并行处理 |
| 基础设施开销 | ~3.7 小时 | 23.4% | Docker 构建、环境设置、测试执行 |
| **总计** | **~16 小时** | **100%** | |

### 1.2 LLM API 详细统计

| 指标 | 值 |
|------|------|
| 总 LLM 时间 (累计) | 98.08 小时 |
| 总迭代次数 | 40,675 |
| 平均每次响应延迟 | 8.68 秒 |
| 平均每实例迭代数 | 81.3 |
| 平均每实例 LLM 时间 | 11.8 分钟 |

### 1.3 基础设施开销分解

| 组件 | 估算耗时 | 说明 |
|------|----------|------|
| Docker 镜像构建 | ~2-3 小时 | 500 实例 × 15-20秒/实例 |
| 环境设置 | ~1-2 小时 | Git checkout、依赖安装 |
| 测试执行 | ~1-2 小时 | 运行测试套件验证修复 |
| 网络延迟与队列 | ~0.5-1 小时 | API 请求排队、网络往返 |
| Worker 协调 | ~0.5 小时 | 任务分配、结果收集 |

---

## 第二部分：迭代效率分析

### 2.1 按解决状态的迭代分布

| 状态 | 实例数 | 平均迭代 | 中位数 | 最小/最大 |
|------|--------|----------|--------|-----------|
| **已解决** | 314 | 78.8 | 79 | 19/100 |
| **未解决** | 173 | 85.2 | 87 | 24/100 |

### 2.2 迭代分布详情

**已解决案例 (314 个):**
| 迭代范围 | 数量 | 占比 |
|----------|------|------|
| 1-25 | 1 | 0.3% |
| 26-50 | 9 | 2.9% |
| 51-75 | 126 | 40.1% |
| 76-100 | 178 | 56.7% |

**未解决案例 (173 个):**
| 迭代范围 | 数量 | 占比 |
|----------|------|------|
| 1-25 | 1 | 0.6% |
| 26-50 | 5 | 2.9% |
| 51-75 | 34 | 19.7% |
| 76-100 | 133 | 76.9% |

### 2.3 关键发现

1. **高迭代使用率**: 96.8% 的实例使用了 51-100 次迭代
2. **未解决案例倾向耗尽迭代**: 76.9% 的失败案例使用了 76-100 次迭代
3. **早期成功罕见**: 仅 3.2% 的已解决案例在 50 次迭代内完成

---

## 第三部分：LLM 延迟分析

### 3.1 按解决状态的延迟统计

| 状态 | 总 LLM 时间 | 调用次数 | 平均延迟 |
|------|------------|----------|----------|
| 已解决 | 58.89 小时 | 24,736 | 8.57 秒 |
| 未解决 | 36.57 小时 | 14,739 | 8.93 秒 |

### 3.2 延迟分布特征

- 未解决案例平均延迟略高 (8.93s vs 8.57s)
- 可能原因：更复杂的上下文导致更长的推理时间
- 延迟波动范围：2-30 秒

---

## 第四部分：Token 使用与成本分析

### 4.1 Token 消耗统计

| 指标 | 值 |
|------|------|
| 总 Prompt Tokens | 1,764,316,046 (1.76B) |
| 总 Completion Tokens | 11,547,369 (11.55M) |
| 平均每实例 Prompt Tokens | 3,528,632 |
| 平均每实例 Completion Tokens | 23,095 |

### 4.2 上下文增长模式

| 指标 | 值 |
|------|------|
| 平均起始上下文 | 8,682 tokens |
| 平均结束上下文 | 70,917 tokens |
| 上下文增长倍数 | 8.2x |

### 4.3 成本估算 (Claude Sonnet 4.5 定价)

| 类型 | 单价 | 费用 |
|------|------|------|
| Input (1.76B tokens) | $3.00/MTok | $5,292.95 |
| Output (11.55M tokens) | $15.00/MTok | $173.21 |
| **总计** | | **$5,466.16** |

**平均每实例成本**: $10.93

---

## 第五部分：优化机会分析

### 5.1 早期停止策略 (针对失败案例)

| 迭代限制 | 影响案例 | 节省迭代 | 节省时间 | 迭代节省率 |
|----------|----------|----------|----------|------------|
| 50 | 167/173 | 6,132 | ~15.2 小时 | 41.6% |
| 60 | 159/173 | 4,480 | ~11.1 小时 | 30.4% |
| 70 | 146/173 | 2,940 | ~7.3 小时 | 19.9% |
| 80 | 114/173 | 1,597 | ~4.0 小时 | 10.8% |

**注意**: 这些是失败案例的理论节省。实际实现需要预测机制来识别可能失败的案例。

### 5.2 预测性早期停止

基于观察到的模式，可以实现智能早期停止：

```python
def should_early_stop(iteration, metrics):
    """
    预测当前实例是否可能最终失败
    """
    # 特征信号
    signals = {
        'repeated_errors': count_repeated_patterns(metrics),
        'no_progress': detect_stagnation(metrics),
        'syntax_errors': count_syntax_errors(metrics),
        'test_failures_stable': test_results_unchanged(metrics),
    }

    # 在 50 次迭代后，如果多个信号触发，考虑停止
    if iteration > 50 and sum(signals.values()) >= 3:
        return True
    return False
```

### 5.3 优化建议总结

#### 短期优化 (无需代码修改)

| 优化项 | 预期收益 | 实施难度 |
|--------|----------|----------|
| 增加并行 workers (8→16) | -40% 时间 | 低 (需更多内存) |
| 预构建 Docker 基础镜像 | -1-2 小时 | 低 |
| Docker build cache 管理 | 稳定性提升 | 低 |
| 降低 max_iterations (100→80) | -10% 时间 | 低 (可能影响准确率) |

#### 中期优化 (需代码修改)

| 优化项 | 预期收益 | 实施难度 |
|--------|----------|----------|
| 智能早期停止 | -20-30% 时间 | 中 |
| 上下文压缩 | -15% tokens | 中 |
| 增量构建缓存 | -30% 构建时间 | 中 |

#### 长期优化 (架构变更)

| 优化项 | 预期收益 | 实施难度 |
|--------|----------|----------|
| 流式 API 调用 | 感知延迟降低 | 高 |
| 预热实例池 | -50% 启动时间 | 高 |
| 分布式评估 | 线性扩展 | 高 |

---

## 第六部分：具体优化方案

### 6.1 方案 A: 增加并行度

**当前配置**: 8 workers
**建议配置**: 16 workers

```bash
# 修改运行命令
./evaluation/benchmarks/swe_bench/scripts/run_infer.sh \
  llm.ppio_claude_sonnet \
  HEAD \
  CodeActAgent \
  500 \
  100 \
  16 \  # 从 8 改为 16
  princeton-nlp/SWE-bench_Verified \
  test
```

**预期效果**:
- 时间: 16小时 → 10小时
- 要求: 至少 64GB 内存

### 6.2 方案 B: 智能迭代限制

```python
# 在 CodeActAgent 中添加早期停止逻辑
class EarlyStopMixin:
    def check_early_stop(self, state):
        iteration = state.iteration

        # 基础规则：50 次迭代后检查
        if iteration < 50:
            return False

        # 检测停滞模式
        recent_actions = state.actions[-10:]
        if self._detect_loop(recent_actions):
            return True

        # 检测持续失败
        if self._test_failures_unchanged(state):
            return True

        return False
```

**预期效果**:
- 时间: 减少 20-30%
- 风险: 可能错过少数后期成功的案例

### 6.3 方案 C: 上下文优化

```python
# 实现上下文压缩
def compress_context(messages, max_tokens=50000):
    """
    压缩对话历史，保留关键信息
    """
    # 保留最新的完整交互
    recent = messages[-5:]

    # 压缩历史消息
    compressed = []
    for msg in messages[:-5]:
        if msg['role'] == 'assistant':
            # 只保留关键决策和代码
            compressed.append(summarize_assistant_message(msg))
        else:
            compressed.append(msg)

    return compressed + recent
```

**预期效果**:
- Token 成本: 减少 30-40%
- 延迟: 减少 15-20% (更短的上下文处理更快)

### 6.4 方案 D: Docker 优化

```bash
# 创建预构建的基础镜像
docker build -t swebench-base:latest -f Dockerfile.base .

# 使用分层缓存
docker buildx create --name swebench-builder \
  --driver docker-container \
  --driver-opt "env.BUILDKIT_GC_POLICY=keep_storage=100GB"

# 定期清理
docker builder prune -f --keep-storage=50GB
```

**预期效果**:
- 构建时间: 减少 50%
- 磁盘使用: 稳定在 100GB 以下

---

## 第七部分：优化优先级建议

### 高优先级 (立即实施)

1. **增加并行度到 16 workers** - 最大单一收益
2. **预构建 Docker 基础镜像** - 减少构建时间
3. **配置 Docker GC 策略** - 防止磁盘溢出

### 中优先级 (下次评估前实施)

4. **实现智能早期停止** - 减少无效迭代
5. **上下文压缩** - 降低成本和延迟

### 低优先级 (长期改进)

6. **分布式评估架构** - 突破单机限制
7. **预热实例池** - 进一步减少启动开销

---

## 第八部分：预期优化效果

### 8.1 综合优化场景

| 场景 | 时间 | 成本 | 说明 |
|------|------|------|------|
| **当前** | 16 小时 | $5,466 | 8 workers, 100 迭代 |
| **方案 A** | 10 小时 | $5,466 | 16 workers |
| **方案 A+B** | 7 小时 | $4,100 | +智能早期停止 |
| **方案 A+B+C** | 6 小时 | $3,000 | +上下文压缩 |
| **完全优化** | 5 小时 | $2,500 | 所有优化 |

### 8.2 优化收益预估

- **时间节省**: 68% (16小时 → 5小时)
- **成本节省**: 54% ($5,466 → $2,500)
- **准确率影响**: ±2% (智能早期停止可能略微降低)

---

## 结论

1. **主要瓶颈**: LLM API 调用时间占 76.6%，是最大的时间消耗源
2. **迭代效率低**: 96.8% 实例使用超过 50 次迭代，存在大量无效计算
3. **基础设施开销**: Docker 构建占约 23% 时间，可通过缓存优化
4. **立即可行的优化**: 增加并行度可将时间从 16 小时减少到 10 小时
5. **长期目标**: 综合优化可将时间减少到 5 小时以内

---

**报告生成时间**: 2026-01-22
**评估模型**: PPIO Claude Sonnet 4.5 (pa/claude-sonnet-4-5-20250929)
**数据集**: princeton-nlp/SWE-bench_Verified
